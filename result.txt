/home/secorec/anaconda3/envs/env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
(481286, 24, 24, 1)
(385028, 24, 24, 1)
(96258, 24, 24, 1)
2018-04-24 14:57:38.598751: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-04-24 14:57:39.194328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:05:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-04-24 14:57:39.194374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0, compute capability: 5.2)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
batch_normalization_1 (Batch (None, 24, 24, 1)         4         
_________________________________________________________________
dropout_1 (Dropout)          (None, 24, 24, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        320       
_________________________________________________________________
activation_1 (Activation)    (None, 24, 24, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 12, 12, 32)        128       
_________________________________________________________________
gaussian_noise_1 (GaussianNo (None, 12, 12, 32)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4608)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               1179904   
_________________________________________________________________
activation_2 (Activation)    (None, 256)               0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 128)               32896     
_________________________________________________________________
activation_3 (Activation)    (None, 128)               0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 128)               512       
_________________________________________________________________
dropout_3 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 129       
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 1,214,917
Trainable params: 1,214,083
Non-trainable params: 834
_________________________________________________________________
Epoch 1/100
3009/3008 [==============================] - 42s 14ms/step - loss: 0.1018 - acc: 0.9643 - val_loss: 0.0312 - val_acc: 0.9917
Epoch 2/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0681 - acc: 0.9771 - val_loss: 0.0213 - val_acc: 0.9942
Epoch 3/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0592 - acc: 0.9807 - val_loss: 0.0268 - val_acc: 0.9932
Epoch 4/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0532 - acc: 0.9830 - val_loss: 0.0167 - val_acc: 0.9946
Epoch 5/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0471 - acc: 0.9847 - val_loss: 0.0148 - val_acc: 0.9953
Epoch 6/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0469 - acc: 0.9849 - val_loss: 0.0223 - val_acc: 0.9933
Epoch 7/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0440 - acc: 0.9855 - val_loss: 0.0163 - val_acc: 0.9955
Epoch 8/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0434 - acc: 0.9863 - val_loss: 0.0123 - val_acc: 0.9965
Epoch 9/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0397 - acc: 0.9872 - val_loss: 0.0133 - val_acc: 0.9960
Epoch 10/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0369 - acc: 0.9878 - val_loss: 0.0103 - val_acc: 0.9967
Epoch 11/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0376 - acc: 0.9876 - val_loss: 0.0095 - val_acc: 0.9969
Epoch 12/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0363 - acc: 0.9879 - val_loss: 0.0143 - val_acc: 0.9957
Epoch 13/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0346 - acc: 0.9889 - val_loss: 0.0202 - val_acc: 0.9950
Epoch 14/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0389 - acc: 0.9875 - val_loss: 0.0092 - val_acc: 0.9972
Epoch 15/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0332 - acc: 0.9892 - val_loss: 0.0205 - val_acc: 0.9950
Epoch 16/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0306 - acc: 0.9899 - val_loss: 0.0081 - val_acc: 0.9974
Epoch 17/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0301 - acc: 0.9902 - val_loss: 0.0098 - val_acc: 0.9969
Epoch 18/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0306 - acc: 0.9900 - val_loss: 0.0098 - val_acc: 0.9968
Epoch 19/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0299 - acc: 0.9903 - val_loss: 0.0108 - val_acc: 0.9963
Epoch 20/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0286 - acc: 0.9907 - val_loss: 0.0099 - val_acc: 0.9969
Epoch 21/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0291 - acc: 0.9906 - val_loss: 0.0122 - val_acc: 0.9969
Epoch 22/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0279 - acc: 0.9907 - val_loss: 0.0086 - val_acc: 0.9974
Epoch 23/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0286 - acc: 0.9905 - val_loss: 0.0083 - val_acc: 0.9973
Epoch 24/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0103 - val_acc: 0.9971
Epoch 25/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0267 - acc: 0.9913 - val_loss: 0.0089 - val_acc: 0.9968
Epoch 26/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0275 - acc: 0.9911 - val_loss: 0.0104 - val_acc: 0.9969
Epoch 27/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0271 - acc: 0.9914 - val_loss: 0.0100 - val_acc: 0.9967
Epoch 28/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0288 - acc: 0.9907 - val_loss: 0.0078 - val_acc: 0.9975
Epoch 29/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0098 - val_acc: 0.9966
Epoch 30/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0251 - acc: 0.9921 - val_loss: 0.0073 - val_acc: 0.9975
Epoch 31/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.0078 - val_acc: 0.9977
Epoch 32/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0225 - acc: 0.9924 - val_loss: 0.0066 - val_acc: 0.9978
Epoch 33/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0092 - val_acc: 0.9970
Epoch 34/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0199 - acc: 0.9934 - val_loss: 0.0064 - val_acc: 0.9978
Epoch 35/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0212 - acc: 0.9934 - val_loss: 0.0057 - val_acc: 0.9980
Epoch 36/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0202 - acc: 0.9933 - val_loss: 0.0058 - val_acc: 0.9980
Epoch 37/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0064 - val_acc: 0.9980
Epoch 38/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0207 - acc: 0.9931 - val_loss: 0.0109 - val_acc: 0.9971
Epoch 39/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0077 - val_acc: 0.9975
Epoch 40/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.0061 - val_acc: 0.9980
Epoch 41/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0193 - acc: 0.9934 - val_loss: 0.0133 - val_acc: 0.9975
Epoch 42/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0059 - val_acc: 0.9980
Epoch 43/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0058 - val_acc: 0.9981
Epoch 44/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0076 - val_acc: 0.9974
Epoch 45/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0073 - val_acc: 0.9977
Epoch 46/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0069 - val_acc: 0.9978
Epoch 47/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0078 - val_acc: 0.9975
Epoch 48/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0057 - val_acc: 0.9980
Epoch 49/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0063 - val_acc: 0.9979
Epoch 50/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0055 - val_acc: 0.9982
Epoch 51/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0074 - val_acc: 0.9975
Epoch 52/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0056 - val_acc: 0.9982
Epoch 53/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0056 - val_acc: 0.9982
Epoch 54/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0158 - acc: 0.9947 - val_loss: 0.0056 - val_acc: 0.9983
Epoch 55/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0063 - val_acc: 0.9980
Epoch 56/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0161 - acc: 0.9943 - val_loss: 0.0059 - val_acc: 0.9981
Epoch 57/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0064 - val_acc: 0.9981
Epoch 58/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0094 - val_acc: 0.9980
Epoch 59/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0062 - val_acc: 0.9981
Epoch 60/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0061 - val_acc: 0.9981
Epoch 61/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0053 - val_acc: 0.9983
Epoch 62/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0058 - val_acc: 0.9981
Epoch 63/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0054 - val_acc: 0.9982
Epoch 64/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0163 - acc: 0.9946 - val_loss: 0.0052 - val_acc: 0.9984
Epoch 65/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0156 - acc: 0.9947 - val_loss: 0.0051 - val_acc: 0.9984
Epoch 66/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0054 - val_acc: 0.9982
Epoch 67/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0054 - val_acc: 0.9982
Epoch 68/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0057 - val_acc: 0.9982
Epoch 69/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0054 - val_acc: 0.9983
Epoch 70/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0150 - acc: 0.9948 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 71/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0052 - val_acc: 0.9982
Epoch 72/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0143 - acc: 0.9951 - val_loss: 0.0052 - val_acc: 0.9982
Epoch 73/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 74/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0052 - val_acc: 0.9983
Epoch 75/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 76/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 77/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 78/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0138 - acc: 0.9952 - val_loss: 0.0054 - val_acc: 0.9982
Epoch 79/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0052 - val_acc: 0.9982
Epoch 80/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.0052 - val_acc: 0.9982
Epoch 81/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0151 - acc: 0.9948 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 82/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0143 - acc: 0.9951 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 83/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0141 - acc: 0.9951 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 84/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0052 - val_acc: 0.9982
Epoch 85/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0054 - val_acc: 0.9982
Epoch 86/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 87/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0050 - val_acc: 0.9983
Epoch 88/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0050 - val_acc: 0.9983
Epoch 89/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0053 - val_acc: 0.9983
Epoch 90/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0052 - val_acc: 0.9983
Epoch 91/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 92/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 93/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 94/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0051 - val_acc: 0.9983
Epoch 95/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0144 - acc: 0.9952 - val_loss: 0.0052 - val_acc: 0.9982
Epoch 96/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0153 - acc: 0.9948 - val_loss: 0.0052 - val_acc: 0.9983
Epoch 97/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.0054 - val_acc: 0.9982
Epoch 98/100
3009/3008 [==============================] - 38s 13ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 99/100
3009/3008 [==============================] - 37s 12ms/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0053 - val_acc: 0.9982
Epoch 100/100
3009/3008 [==============================] - 38s 12ms/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0053 - val_acc: 0.9982
96258/96258 [==============================] - 9s 97us/step
Test loss: 0.005275454010646193
Test accuracy: 0.18076419622264916 %
[[1]
 [1]
 [1]
 ...
 [0]
 [0]
 [0]]

_________________Test Confusion Matrix_________________
[[55771   125]
 [   49 40313]]
______________________Test Report______________________
             precision    recall  f1-score   support

        0.0       1.00      1.00      1.00     55896
        1.0       1.00      1.00      1.00     40362

avg / total       1.00      1.00      1.00     96258
